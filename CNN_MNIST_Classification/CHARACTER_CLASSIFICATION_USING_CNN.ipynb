{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<center><h1> Alphabet and Digit recognition using Convolution Neural Network  </h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Importing Required Librarires</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WOE990-u4NZp"
   },
   "outputs": [],
   "source": [
    "# import Numpy and Pandas for handling arrays and loading csv files\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# for reading and displaying images, import imread and matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for creating validation set, import train_test_split; understand how the function works\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for evaluating the model, import accuracy_score from sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Import necessary PyTorch libraries and modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Import dataset from pytorch vision -  MNIST\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>********************* Digit Classification ********************</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading MNIST dataset from torchvision<br>\n",
    "About MNIST Dataset:<br>\n",
    "<ul>\n",
    "    <li> Dataset for Handwritten digits</li>\n",
    "    <li> Consist of 60000 images for training and 10000 images for testing</li>\n",
    "    <li> Images has dimension / pixel of 28 x 28 in gray scale</li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "E5dOKNMc4zkf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b3292cbfb34fab81d24b2ca4384293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e813d42c8224e908ef7e494be719c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af910f76ce74dbfb81685075e78f0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e4dd70d14cb4dbda8fa6fa7fa476229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\torch\\csrc\\utils\\tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# load dataset and use dataloader to send the data in batches.\n",
    "\n",
    "# transforms is used to Convert data/PIL images  to tensor and normalise it.\n",
    "# Its needed because Images are in the format of PIL Images so to convert\n",
    "# into tensor and to normalize as the number are ranging from 0 to 255.\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "# Loading training images after downloading with transforming simultaneously using transform variable\n",
    "Dig_trainset = torchvision.datasets.MNIST(root='./data', train=True,download=True, transform=transform)\n",
    "\n",
    "# DataLoader is use to pass data in batches while training or whenever it is required.\n",
    "Dig_trainloader = torch.utils.data.DataLoader(Dig_trainset, batch_size=4,shuffle=True, num_workers=2)\n",
    "\n",
    "# Loading testing images after downloading with transforming simultaneously using transform variable\n",
    "Dig_testset = torchvision.datasets.MNIST(root='./data', train=False,download=True, transform=transform)\n",
    "\n",
    "# DataLoader is use to pass data in batches while training or whenever it is required.\n",
    "Dig_testloader = torch.utils.data.DataLoader(Dig_testset, batch_size=4,shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AADCfdBXha-1",
    "outputId": "e8f843fe-cc05-4e00-b93f-53434267ae17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training set :  60000\n",
      "torch.Size([1, 28, 28])\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Checking the length of training set of digit dataset\n",
    "print(\"Length of training set : \",len(Dig_trainset))\n",
    "image,label=Dig_trainset[0]\n",
    "print(image.shape)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    },
    "id": "WDOizFTC5O-e",
    "outputId": "f450d16b-d4a3-4e2e-e16c-3d0c8fd220ae"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3) tensor(5) tensor(0) tensor(6)\n"
     ]
    }
   ],
   "source": [
    "# Visualise some random images from the dataset.\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images with the help of data iterator\n",
    "dataiter = iter(Dig_trainloader)\n",
    "images, labels = dataiter.next()\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % labels[j] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MIylgRAp5YcY"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Class 'Net_for_Dig' which is used to create convolution neural network for \n",
    "classification of digit and it is a sub class which uses its super class \n",
    "namely 'nn.Module' which is provided by torch library.There are following funtions:\n",
    "\n",
    "        1. __init__ : This Function is always required for a class which is used\n",
    "                      to initialise variables. Here, this class first initialised\n",
    "                      variables of its super class.Then, it initialised its own \n",
    "                      variables which are basically layers of convolution neural\n",
    "                      network.\n",
    "                      First Variable is \"conv1\" which is first Convolution layer of \n",
    "                      network which is initialised with inbuilt convolution layer \n",
    "                      provided by torch.nn .This layer will accept the inputs in batches\n",
    "                      with one channel, then it outputs 32 channels with the help of\n",
    "                      kernel of size 3 and padding 1.\n",
    "                      \n",
    "                      Second Variable is \"pool\" which is initialised with Max Pool Layer\n",
    "                      provided by torch.nn with kernel size 2 and stride 2.This layer \n",
    "                      can be used after any layer whenever we want to reduce the dimension.\n",
    "                      \n",
    "                      Third Variable is \"conv2\" which is second Convolution layer of \n",
    "                      network which is initialised with inbuilt convolution layer \n",
    "                      provided by torch.nn .This layer will accept the inputs in batches\n",
    "                      with 32 channel (output by previous layer), then it outputs 64 channels\n",
    "                      with the help of kernel of size 3.\n",
    "                      \n",
    "                      Fourth Variable is \"fc1\" which is first fully connected layer of the neural\n",
    "                      network initialised with help of torch.nn.Linear which is linear layer\n",
    "                      of network.This object takes input of 64*6*6 (This can be decided on \n",
    "                      our own) and it outputs 600 units(decided on our own).\n",
    "                      \n",
    "                      Fifth Variable is \"drop\" which is object of dropout layer which is\n",
    "                      used to prevent the model from overfitting.Layer is provided by \n",
    "                      torch.nn .It takes probability( values getting 0) as input.\n",
    "                      \n",
    "                      Sixth Variable is \"fc2\" which is second fully connected layer of the neural\n",
    "                      network initialised with help of torch.nn.Linear which is linear layer\n",
    "                      of network.This object takes input of 600 ( output from previous layer)\n",
    "                      and it outputs 120 units(decided on our own).\n",
    "                      \n",
    "                      Seventh Variable is \"fc3\" which is last fully connected layer of the neural\n",
    "                      network initialised with help of torch.nn.Linear which is linear layer\n",
    "                      of network.This object takes input of 120 ( output from previous layer)\n",
    "                      and it outputs 10 units(total number of classes).\n",
    "                      \n",
    "        2. forward: This Function is used to forward propagate in the neural network which is\n",
    "                    called by it super class.This function is provided by the input that we are\n",
    "                    going to feed in the neural network.\n",
    "                    Flow of the network:\n",
    "                    1.Feeded to convolution layer 1\n",
    "                    2.Passed through ReLU Layer (Activation Layer)\n",
    "                    3.Passed through Max Pooling Layer\n",
    "                    4.Feeded to convolution layer 2\n",
    "                    5.Passed through ReLU Layer (Activation Layer)\n",
    "                    6.Passed through Max Pooling Layer\n",
    "                    \n",
    "                    Squeezed all values to one dimension so that it can be feeded in Linear Layer\n",
    "                    \n",
    "                    7.Passed through Fully Connected Layer 1\n",
    "                    8.Passed through ReLU Layer(Activation Layer)\n",
    "                    9.Passed through Dropout Layer\n",
    "                    10.Passed through Fully Connected Layer 2\n",
    "                    11.Passed through ReLU Layer(Activation Layer)\n",
    "                    12.Passed through Last Fully connected layer.\n",
    "                    \n",
    "                    Last Layer give the pobabilty of the classes from which answer will be the \n",
    "                    class which has max probability.\n",
    "                    This value is returned by this function.\n",
    "                    \n",
    "'''\n",
    "class Net_for_Dig(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_for_Dig, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(in_features=64*6*6, out_features=600)\n",
    "        self.drop = nn.Dropout2d(0.25)\n",
    "        self.fc2 = nn.Linear(in_features=600, out_features=120)\n",
    "        self.fc3 = nn.Linear(in_features=120, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sfZMqLIy5-HV",
    "outputId": "9030555b-acaa-41a7-e990-1c6cc0baf5e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] CELloss: 0.357\n",
      "[1,  4000] CELloss: 0.138\n",
      "[1,  6000] CELloss: 0.123\n",
      "[1,  8000] CELloss: 0.098\n",
      "[1, 10000] CELloss: 0.092\n",
      "[1, 12000] CELloss: 0.089\n",
      "[1, 14000] CELloss: 0.076\n",
      "[2,  2000] CELloss: 0.065\n",
      "[2,  4000] CELloss: 0.083\n",
      "[2,  6000] CELloss: 0.073\n",
      "[2,  8000] CELloss: 0.066\n",
      "[2, 10000] CELloss: 0.060\n",
      "[2, 12000] CELloss: 0.060\n",
      "[2, 14000] CELloss: 0.079\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#******************************ADAM as OPTIMIZER && CROSS ENTROPY as LOSS Func********************************\n",
    "# Define training the model\n",
    "Dig_net = Net_for_Dig()\n",
    "\n",
    "# defining the optimizer\n",
    "optimizer = optim.Adam(Dig_net.parameters(), lr=0.001)\n",
    "\n",
    "# defining the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# For each epoch and in each batch:\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(Dig_trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # compute the model output\n",
    "        outputs = Dig_net(inputs)\n",
    "        \n",
    "        # calculate loss\n",
    "        CELloss = criterion(outputs, labels)\n",
    "        \n",
    "        # propagate loss backwards\n",
    "        CELloss.backward()\n",
    "        \n",
    "        # update model weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += CELloss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] CELloss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "addIvU2e5exn"
   },
   "outputs": [],
   "source": [
    "#Saving the trained model in the PATH\n",
    "PATH = './Adam_CEL_MNIST_net_ep2.pth'\n",
    "torch.save(Dig_net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing back all parameters learnt when trained\n",
    "PATH = './Adam_CEL_MNIST_net_ep2.pth'\n",
    "Dig_net = Net_for_Dig()\n",
    "Dig_net.load_state_dict(torch.load(PATH))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learnt Weights and bias for each layer of Convolution Neural Network Dig_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of the layer:  conv1.weight\n",
      "Parameters:  Parameter containing:\n",
      "tensor([[[[ 0.0230, -0.0309, -0.2474],\n",
      "          [ 0.0524, -0.2072,  0.0135],\n",
      "          [-0.1576, -0.0854, -0.1005]]],\n",
      "\n",
      "\n",
      "        [[[-0.1347,  0.0317,  0.1673],\n",
      "          [-0.2085,  0.2400, -0.1062],\n",
      "          [ 0.3054, -0.0598, -0.0391]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2472,  0.0081, -0.0302],\n",
      "          [ 0.1434, -0.1599, -0.1067],\n",
      "          [-0.1013, -0.2294,  0.0653]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1059, -0.2658,  0.1164],\n",
      "          [-0.1122,  0.1683, -0.1027],\n",
      "          [-0.1957,  0.0457, -0.0534]]],\n",
      "\n",
      "\n",
      "        [[[-0.0174, -0.1229,  0.1159],\n",
      "          [ 0.0083, -0.2369,  0.1579],\n",
      "          [ 0.1469, -0.1764,  0.1084]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0775, -0.1984,  0.0273],\n",
      "          [ 0.1403,  0.1210, -0.1765],\n",
      "          [-0.0611,  0.2196, -0.1880]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1537,  0.1196, -0.2961],\n",
      "          [ 0.3834, -0.1810, -0.0829],\n",
      "          [ 0.0128,  0.2333, -0.0027]]],\n",
      "\n",
      "\n",
      "        [[[-0.0735,  0.1147,  0.1634],\n",
      "          [ 0.2041, -0.1181, -0.0268],\n",
      "          [-0.1504, -0.0679,  0.1417]]],\n",
      "\n",
      "\n",
      "        [[[-0.0321,  0.0142,  0.0153],\n",
      "          [ 0.0265, -0.0203, -0.0832],\n",
      "          [ 0.0115, -0.1205,  0.2747]]],\n",
      "\n",
      "\n",
      "        [[[-0.1602,  0.1959, -0.0036],\n",
      "          [-0.1462, -0.0450,  0.2476],\n",
      "          [-0.0158, -0.1787,  0.2189]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0891,  0.0558, -0.0715],\n",
      "          [ 0.0039, -0.0656,  0.0838],\n",
      "          [ 0.0388, -0.0538, -0.0010]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1495,  0.1025, -0.1276],\n",
      "          [ 0.0379, -0.3103,  0.2283],\n",
      "          [ 0.2017, -0.2229,  0.2134]]],\n",
      "\n",
      "\n",
      "        [[[-0.2187,  0.3252, -0.2124],\n",
      "          [ 0.1230,  0.0671, -0.1737],\n",
      "          [ 0.0608, -0.0273, -0.1399]]],\n",
      "\n",
      "\n",
      "        [[[-0.0629, -0.0582,  0.0673],\n",
      "          [ 0.0095,  0.1136, -0.1153],\n",
      "          [-0.0310, -0.0901,  0.0499]]],\n",
      "\n",
      "\n",
      "        [[[-0.1221, -0.3670,  0.1332],\n",
      "          [ 0.1448,  0.0149,  0.1876],\n",
      "          [ 0.0904, -0.0029, -0.1350]]],\n",
      "\n",
      "\n",
      "        [[[-0.1600,  0.2122,  0.2057],\n",
      "          [-0.1749, -0.1743, -0.1349],\n",
      "          [ 0.1198, -0.0333,  0.0388]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0928,  0.0836,  0.1025],\n",
      "          [ 0.0345,  0.0677, -0.0222],\n",
      "          [ 0.0256, -0.1940, -0.1703]]],\n",
      "\n",
      "\n",
      "        [[[-0.0336, -0.2309, -0.1063],\n",
      "          [-0.1367, -0.0994, -0.0250],\n",
      "          [-0.2642, -0.0148, -0.1973]]],\n",
      "\n",
      "\n",
      "        [[[-0.1683,  0.1537, -0.0713],\n",
      "          [-0.0100, -0.2899, -0.0728],\n",
      "          [ 0.1888,  0.0548, -0.0514]]],\n",
      "\n",
      "\n",
      "        [[[-0.0817,  0.2339, -0.1518],\n",
      "          [ 0.1395, -0.0954, -0.0642],\n",
      "          [-0.0313, -0.0751, -0.0440]]],\n",
      "\n",
      "\n",
      "        [[[-0.0397, -0.0658, -0.1083],\n",
      "          [ 0.1580,  0.1128, -0.1750],\n",
      "          [ 0.0103, -0.1281,  0.2545]]],\n",
      "\n",
      "\n",
      "        [[[-0.1210,  0.2551, -0.0872],\n",
      "          [ 0.2557, -0.2378, -0.1708],\n",
      "          [-0.2639, -0.0478,  0.3670]]],\n",
      "\n",
      "\n",
      "        [[[-0.1064, -0.1201,  0.1712],\n",
      "          [-0.3312,  0.1824,  0.0858],\n",
      "          [ 0.2556, -0.0367, -0.0520]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1502, -0.0456,  0.1841],\n",
      "          [-0.1023, -0.3449,  0.1494],\n",
      "          [-0.1798,  0.3026,  0.0353]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1880,  0.2912, -0.3037],\n",
      "          [-0.2604,  0.3227,  0.1180],\n",
      "          [-0.1972, -0.2173,  0.0705]]],\n",
      "\n",
      "\n",
      "        [[[-0.2920, -0.0822,  0.1349],\n",
      "          [ 0.1223,  0.3520, -0.0125],\n",
      "          [-0.1007, -0.1520, -0.2041]]],\n",
      "\n",
      "\n",
      "        [[[-0.0697,  0.1265, -0.0126],\n",
      "          [ 0.1009, -0.1734,  0.0861],\n",
      "          [-0.0290,  0.0077,  0.0094]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1157,  0.1992, -0.1343],\n",
      "          [-0.2516, -0.2441, -0.2585],\n",
      "          [ 0.1857,  0.3621,  0.1119]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3375,  0.2316,  0.2317],\n",
      "          [ 0.0140, -0.2710, -0.0913],\n",
      "          [-0.3289,  0.1123,  0.0219]]],\n",
      "\n",
      "\n",
      "        [[[-0.2493, -0.1339,  0.3041],\n",
      "          [ 0.0956, -0.1276, -0.2351],\n",
      "          [ 0.2324, -0.0023, -0.1294]]],\n",
      "\n",
      "\n",
      "        [[[-0.0895,  0.1475, -0.2866],\n",
      "          [-0.3385,  0.3513, -0.1361],\n",
      "          [ 0.0883,  0.1242, -0.2105]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1827, -0.2073,  0.0899],\n",
      "          [-0.2187,  0.0751, -0.0434],\n",
      "          [ 0.1243, -0.0334,  0.1085]]]], requires_grad=True)\n",
      "Name of the layer:  conv1.bias\n",
      "Parameters:  Parameter containing:\n",
      "tensor([-0.3598, -0.3030, -0.3701, -0.5581, -0.4050, -0.3343, -0.3404, -0.3451,\n",
      "        -0.3723, -0.3430, -0.3565, -0.3594, -0.4543, -0.3224, -0.2247, -0.4710,\n",
      "        -0.1713, -0.5088, -0.3304, -0.3450, -0.3091, -0.4647, -0.3790, -0.4037,\n",
      "        -0.3515, -0.3727, -0.2804, -0.2766, -0.3155, -0.3927, -0.5085, -0.2097],\n",
      "       requires_grad=True)\n",
      "Name of the layer:  conv2.weight\n",
      "Parameters:  Parameter containing:\n",
      "tensor([[[[ 7.1413e-02,  5.6018e-02, -6.3183e-02],\n",
      "          [ 1.3356e-02, -1.4092e-01, -5.8820e-02],\n",
      "          [-2.0084e-01, -2.9892e-01, -2.0304e-01]],\n",
      "\n",
      "         [[-1.0341e-01, -2.5001e-01, -1.5622e-02],\n",
      "          [-3.7379e-02, -1.0370e-01,  1.6873e-01],\n",
      "          [-4.3427e-03, -3.1463e-02,  1.0665e-01]],\n",
      "\n",
      "         [[-6.9721e-02, -5.2359e-02,  3.4549e-02],\n",
      "          [-1.4368e-01, -1.7658e-01, -2.8595e-01],\n",
      "          [-4.5769e-03, -2.2222e-01, -5.5642e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.0031e-02, -1.0233e-01,  4.8659e-02],\n",
      "          [-1.5174e-01, -1.5486e-01, -7.4749e-02],\n",
      "          [-7.6447e-02, -1.3506e-02, -3.6440e-02]],\n",
      "\n",
      "         [[-5.9322e-03, -1.1489e-01, -1.3798e-01],\n",
      "          [ 1.1272e-01,  7.5788e-02, -1.9015e-01],\n",
      "          [ 3.4113e-02, -4.3357e-02,  2.0936e-02]],\n",
      "\n",
      "         [[-2.7186e-02, -1.5582e-01, -8.6333e-02],\n",
      "          [-7.5111e-02,  2.8435e-03, -3.0206e-01],\n",
      "          [-2.2112e-01, -1.9228e-01, -2.8301e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.5107e-02, -2.9250e-02, -5.7683e-02],\n",
      "          [-8.3657e-02, -2.3237e-02,  2.0695e-02],\n",
      "          [-4.9476e-02, -5.4648e-02, -8.4397e-03]],\n",
      "\n",
      "         [[-1.8504e-02,  6.2690e-03,  1.5881e-02],\n",
      "          [-2.7615e-02, -1.1444e-01,  6.8824e-03],\n",
      "          [ 2.8775e-02, -3.2594e-03, -3.1150e-02]],\n",
      "\n",
      "         [[-8.7100e-02, -4.4649e-02,  1.8022e-02],\n",
      "          [ 5.7489e-03, -1.0206e-01, -2.7886e-02],\n",
      "          [-3.0211e-02, -8.8624e-02, -4.4481e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.6681e-02, -7.4505e-02, -1.2368e-01],\n",
      "          [-8.5061e-02,  2.6339e-02, -2.5179e-02],\n",
      "          [-2.9183e-02, -2.6502e-02, -3.2285e-02]],\n",
      "\n",
      "         [[ 7.9230e-02,  1.0639e-01,  2.4150e-02],\n",
      "          [ 4.7442e-02,  8.1692e-02, -7.2804e-03],\n",
      "          [ 8.3790e-02, -5.0883e-03,  1.1369e-01]],\n",
      "\n",
      "         [[ 1.7384e-02,  1.4346e-02, -9.9953e-02],\n",
      "          [-5.7435e-02, -1.0088e-01, -2.2377e-02],\n",
      "          [-1.4970e-02, -6.7759e-02, -1.0832e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4733e-02,  2.9973e-02, -3.7728e-02],\n",
      "          [-1.0225e-01, -1.0217e-01, -1.2223e-01],\n",
      "          [-1.1703e-01, -4.7989e-02, -1.4323e-02]],\n",
      "\n",
      "         [[-2.5994e-02, -9.8324e-02, -4.2465e-02],\n",
      "          [ 7.0422e-04, -1.1847e-01, -2.4391e-02],\n",
      "          [-3.7187e-02, -1.3432e-01, -5.6780e-02]],\n",
      "\n",
      "         [[-1.7145e-02, -4.4006e-02, -7.9376e-02],\n",
      "          [ 2.5829e-02,  1.4561e-02,  2.4962e-02],\n",
      "          [-9.1203e-03, -2.6420e-02, -3.7763e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3086e-02, -8.0466e-02, -1.2734e-01],\n",
      "          [-1.3386e-01, -8.6622e-02, -6.7194e-02],\n",
      "          [-7.4512e-02, -1.5347e-01,  1.5562e-02]],\n",
      "\n",
      "         [[ 3.1315e-02, -4.8928e-02, -5.8487e-02],\n",
      "          [-1.5501e-02, -6.5844e-02, -3.4503e-02],\n",
      "          [-2.5026e-02, -8.8941e-02, -2.0256e-02]],\n",
      "\n",
      "         [[-1.0357e-01, -5.1045e-02, -1.1832e-01],\n",
      "          [-4.9056e-02, -2.5888e-02, -5.2353e-02],\n",
      "          [ 6.8328e-03, -6.4466e-02, -6.8874e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.3489e-02, -7.1009e-02, -7.4249e-02],\n",
      "          [ 4.6850e-02, -1.2029e-01, -1.2401e-02],\n",
      "          [ 7.9160e-02, -2.5055e-01,  1.8081e-02]],\n",
      "\n",
      "         [[-1.2135e-01,  7.1290e-02,  3.4845e-02],\n",
      "          [-1.6921e-01, -1.6115e-02, -2.1211e-01],\n",
      "          [-1.3745e-01,  7.9801e-02, -2.0482e-01]],\n",
      "\n",
      "         [[ 7.5694e-02,  1.5390e-02,  1.8318e-01],\n",
      "          [-8.4817e-02, -8.0578e-02,  9.4850e-02],\n",
      "          [-2.2954e-01,  5.2677e-02, -1.9038e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.0797e-01, -2.7867e-01,  1.2207e-01],\n",
      "          [-2.9914e-01, -1.1189e-01, -3.2436e-02],\n",
      "          [-1.4952e-01,  1.3729e-01, -4.9042e-01]],\n",
      "\n",
      "         [[-3.5933e-01,  1.2513e-01, -8.7628e-02],\n",
      "          [-3.2335e-01,  2.0395e-01,  6.5740e-02],\n",
      "          [-9.5340e-02,  1.3887e-01,  1.1696e-01]],\n",
      "\n",
      "         [[ 3.1429e-02, -1.9578e-02,  2.2728e-01],\n",
      "          [-1.9025e-01, -1.2960e-01, -2.6386e-04],\n",
      "          [ 1.2994e-02, -1.3101e-01, -2.8254e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.0779e-01, -2.9634e-01, -2.8151e-01],\n",
      "          [-1.7270e-01, -1.8176e-01, -1.4589e-01],\n",
      "          [-5.7934e-02, -1.8243e-01, -7.5174e-02]],\n",
      "\n",
      "         [[ 5.1219e-02, -1.1761e-01, -1.2750e-01],\n",
      "          [ 1.1705e-01, -1.3761e-01, -3.0718e-01],\n",
      "          [ 1.2452e-02, -1.1106e-02, -1.9332e-01]],\n",
      "\n",
      "         [[-2.3324e-01, -2.3537e-01,  8.2007e-02],\n",
      "          [-1.2219e-01, -1.7735e-01, -6.9391e-02],\n",
      "          [ 1.1857e-01, -1.1649e-01, -5.9537e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.7179e-01, -2.8483e-01,  2.0495e-01],\n",
      "          [-1.1665e-01, -3.9396e-01,  1.3038e-01],\n",
      "          [-1.9269e-01, -2.6133e-01,  7.5626e-02]],\n",
      "\n",
      "         [[-1.6337e-01, -1.6482e-01,  4.5657e-03],\n",
      "          [-1.7948e-02, -6.7511e-02,  1.8499e-01],\n",
      "          [ 1.5736e-01, -9.4574e-02,  8.5655e-02]],\n",
      "\n",
      "         [[ 7.8309e-03, -1.0481e-01, -9.9548e-02],\n",
      "          [ 7.5338e-02, -2.2593e-01, -1.6558e-01],\n",
      "          [ 1.6174e-01, -5.6615e-02, -3.3310e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1194e-02, -3.9877e-02, -4.6014e-02],\n",
      "          [-2.4642e-02, -1.1082e-02, -8.2391e-02],\n",
      "          [-4.1984e-02, -3.4590e-02, -2.7332e-02]],\n",
      "\n",
      "         [[-3.8197e-02, -1.9360e-02,  3.1762e-02],\n",
      "          [ 3.1348e-02,  9.6960e-04, -4.3844e-02],\n",
      "          [-2.6065e-02,  4.4065e-02, -5.5271e-02]],\n",
      "\n",
      "         [[ 4.1619e-03, -5.0813e-03, -6.4868e-02],\n",
      "          [ 1.0375e-04, -8.0109e-02, -1.2894e-02],\n",
      "          [ 3.3849e-02,  4.7030e-02,  3.3948e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.4629e-02, -3.0302e-02, -9.7856e-04],\n",
      "          [ 1.5963e-02,  3.6893e-02, -7.2392e-03],\n",
      "          [-2.0454e-02, -5.9928e-02, -4.7832e-02]],\n",
      "\n",
      "         [[-1.2855e-02,  1.9610e-02, -3.0091e-02],\n",
      "          [-8.6074e-03,  3.1678e-02,  2.8142e-02],\n",
      "          [-3.3005e-02,  6.0099e-04,  3.6848e-02]],\n",
      "\n",
      "         [[-5.0357e-02, -5.7640e-02,  1.2974e-02],\n",
      "          [ 1.8163e-02, -5.9758e-02, -5.2722e-02],\n",
      "          [ 4.4188e-04,  1.5795e-02, -7.1953e-02]]]], requires_grad=True)\n",
      "Name of the layer:  conv2.bias\n",
      "Parameters:  Parameter containing:\n",
      "tensor([-0.0073, -0.0305, -0.0206, -0.0316, -0.0133, -0.0915, -0.0368, -0.1037,\n",
      "        -0.0178,  0.1276, -0.0592, -0.0246, -0.0316, -0.0424, -0.0387, -0.0435,\n",
      "        -0.0490, -0.0173, -0.1066, -0.0116, -0.0574, -0.1012,  0.0035, -0.0334,\n",
      "        -0.0405, -0.0156, -0.0325,  0.0023, -0.0341, -0.0304, -0.0046, -0.0803,\n",
      "        -0.0255, -0.0986, -0.0892, -0.0062, -0.0411, -0.0385, -0.0898, -0.0258,\n",
      "        -0.1289, -0.0595, -0.0650, -0.0821, -0.0353, -0.1182, -0.0742, -0.0431,\n",
      "        -0.0761, -0.0799, -0.1542, -0.0449, -0.0429, -0.0686, -0.0370, -0.1122,\n",
      "        -0.0212, -0.0653, -0.0735, -0.0070, -0.0661,  0.0188, -0.0813, -0.0910],\n",
      "       requires_grad=True)\n",
      "Name of the layer:  fc1.weight\n",
      "Parameters:  Parameter containing:\n",
      "tensor([[-0.0104,  0.0612,  0.0764,  ..., -0.0094,  0.0121,  0.0052],\n",
      "        [-0.0059, -0.0675,  0.0902,  ...,  0.0166, -0.0058,  0.0136],\n",
      "        [ 0.0208,  0.0548,  0.1185,  ...,  0.0050, -0.0093, -0.0148],\n",
      "        ...,\n",
      "        [-0.0122,  0.0050, -0.0021,  ..., -0.0121, -0.0033,  0.0095],\n",
      "        [-0.0066,  0.0005,  0.0019,  ..., -0.0111,  0.0071, -0.0065],\n",
      "        [-0.0156, -0.0032,  0.0161,  ...,  0.0104, -0.0126, -0.0114]],\n",
      "       requires_grad=True)\n",
      "Name of the layer:  fc1.bias\n",
      "Parameters:  Parameter containing:\n",
      "tensor([-2.5561e-02, -1.6880e-01, -3.2937e-01, -6.4507e-02, -3.1103e-01,\n",
      "        -2.0238e-01, -3.9762e-02, -1.5012e-01, -4.2192e-02,  3.7865e-02,\n",
      "        -3.0459e-01, -1.3529e-02,  6.1744e-02, -4.2684e-02, -4.7160e-02,\n",
      "        -1.6431e-01, -7.9781e-02, -2.8460e-02,  6.9291e-03, -9.1482e-02,\n",
      "        -2.1037e-01, -1.2601e-02,  8.3220e-03, -3.3868e-02, -9.2088e-02,\n",
      "        -5.8401e-02, -1.6953e-02, -8.9229e-02, -2.1303e-01, -8.5700e-02,\n",
      "         8.0101e-03, -1.9908e-01, -2.6090e-01, -3.9407e-02, -1.6769e-01,\n",
      "         4.8756e-02, -1.2356e-01, -8.2995e-02, -2.8492e-01, -1.0467e-01,\n",
      "         4.9385e-02, -1.3794e-01, -4.1876e-02, -2.3282e-01,  1.2046e-02,\n",
      "        -4.1096e-02, -1.9837e-02, -1.9822e-02, -2.6238e-01, -2.6848e-01,\n",
      "        -1.0471e-01, -1.2709e-01, -3.4335e-02,  7.1571e-02, -3.8521e-02,\n",
      "        -1.3852e-02, -1.2175e-02,  1.3870e-02, -2.7169e-01, -1.2391e-01,\n",
      "        -2.6417e-02, -1.5065e-02, -7.6778e-02, -1.0942e-01, -1.9245e-02,\n",
      "        -1.9583e-01, -1.2185e-01, -1.2880e-01, -1.1251e-02, -2.1038e-02,\n",
      "        -1.1767e-01, -2.7830e-01, -1.0527e-01, -5.2504e-02, -2.3504e-01,\n",
      "        -1.0211e-01,  8.1981e-02, -1.9395e-02, -3.3046e-03,  3.8937e-02,\n",
      "        -3.1526e-02, -1.1127e-01, -6.1251e-02, -1.1546e-02, -1.2286e-02,\n",
      "        -3.9083e-02, -1.6404e-02, -2.4092e-02, -5.0146e-02, -1.8012e-01,\n",
      "        -3.9971e-02, -2.0523e-02, -3.1768e-02, -4.3038e-02, -2.1416e-01,\n",
      "        -3.6550e-01, -1.0245e-01,  4.1552e-02, -8.0539e-02, -2.9085e-01,\n",
      "        -6.4452e-02, -7.2047e-03, -1.1423e-01,  7.5535e-02, -1.2765e-01,\n",
      "         7.1895e-02, -1.8959e-01, -1.8938e-02, -3.6808e-02, -3.0979e-02,\n",
      "        -6.8633e-02, -4.3715e-02, -9.4465e-02, -1.7108e-02, -6.9866e-02,\n",
      "        -1.8665e-01, -1.8550e-02, -2.3145e-01, -9.8006e-02, -6.0661e-02,\n",
      "        -6.5862e-02,  2.1348e-02, -1.8152e-01, -1.7720e-01, -3.6995e-02,\n",
      "         3.4972e-02, -4.8107e-02, -2.0283e-01,  6.1855e-02, -2.1322e-01,\n",
      "        -3.8114e-01, -6.7826e-02, -9.3506e-02, -9.8522e-03,  3.5866e-02,\n",
      "        -1.2914e-01, -5.0303e-02, -1.8734e-01, -3.7496e-02, -1.5216e-01,\n",
      "        -1.5427e-01, -1.2300e-01, -2.9917e-01, -3.1587e-02, -2.1713e-01,\n",
      "        -2.9240e-02, -1.7988e-01, -1.2675e-01, -3.4062e-02,  6.4084e-02,\n",
      "        -1.6496e-01,  3.8165e-02, -3.2258e-01,  4.0946e-02, -1.3857e-01,\n",
      "        -2.4341e-01, -3.3831e-02, -7.6517e-02,  3.1141e-03,  4.3181e-02,\n",
      "        -1.7818e-01, -3.2878e-01,  2.6578e-04, -1.6913e-01, -4.5924e-02,\n",
      "        -2.6498e-01, -6.3932e-02, -3.6669e-01, -1.7713e-01, -1.4833e-01,\n",
      "         2.6739e-02, -2.1155e-02, -5.8211e-03, -5.3187e-03, -1.5054e-01,\n",
      "        -1.2905e-01, -2.2688e-02, -1.1465e-01, -4.4174e-03, -3.7440e-02,\n",
      "        -2.1543e-02, -1.4958e-02,  5.7169e-02, -1.2521e-01, -2.2314e-01,\n",
      "        -3.7680e-02, -2.5708e-02, -3.8920e-02,  2.2580e-02, -4.4028e-02,\n",
      "         1.0624e-01, -1.4978e-01, -4.3834e-02, -9.0349e-02,  7.8798e-03,\n",
      "        -8.6469e-02, -5.1355e-02,  4.0853e-03, -2.3795e-02, -2.1467e-01,\n",
      "        -1.5974e-01, -3.9866e-02, -1.7449e-01, -2.9309e-02, -4.8431e-02,\n",
      "        -6.1837e-02, -6.2366e-02, -3.7736e-02, -3.2830e-01, -4.7169e-02,\n",
      "        -2.9362e-02, -1.1539e-02, -1.5842e-01, -1.8070e-02, -1.1208e-01,\n",
      "        -2.3406e-01,  8.9512e-03,  1.0320e-02,  5.4114e-02, -1.2590e-01,\n",
      "        -9.8777e-03, -2.0784e-02, -7.9512e-02, -4.3015e-01, -2.2546e-01,\n",
      "        -3.9303e-02, -1.6203e-01, -1.5451e-01, -1.2975e-01, -2.3428e-01,\n",
      "        -1.3593e-01, -1.6364e-01, -2.7295e-02, -2.7907e-01,  1.8379e-02,\n",
      "        -2.9630e-01,  7.3930e-03, -1.4456e-01, -1.2135e-01,  3.6168e-02,\n",
      "        -2.1255e-01, -6.9986e-02, -7.0663e-02, -3.7651e-02,  4.8278e-02,\n",
      "        -7.4455e-02, -2.1125e-01, -6.2678e-02, -8.2931e-02, -5.8291e-02,\n",
      "        -3.0121e-02, -7.5459e-02, -2.7946e-02, -9.7261e-02, -2.6895e-02,\n",
      "        -3.7165e-02, -2.0424e-01, -1.3507e-02,  5.2105e-03,  9.0514e-02,\n",
      "        -5.9338e-02, -5.7491e-02,  4.6045e-02, -7.7624e-02, -1.1902e-01,\n",
      "        -2.1508e-01, -2.1323e-01, -1.1701e-01, -4.0433e-02, -1.6489e-01,\n",
      "         8.9924e-02, -1.3047e-01, -1.9447e-01, -5.2047e-02, -3.0304e-01,\n",
      "        -3.1515e-03, -1.3660e-01,  1.0844e-01, -1.2726e-02,  7.0003e-03,\n",
      "         7.4744e-02,  2.5953e-03, -2.0814e-01, -1.2336e-02, -3.7471e-02,\n",
      "        -1.8055e-02, -1.3569e-01,  3.3125e-02, -2.4198e-01, -3.6627e-03,\n",
      "        -8.8183e-02, -1.2859e-01, -2.2019e-01, -1.6401e-02,  2.0084e-02,\n",
      "        -1.6923e-02, -3.3138e-02, -2.9097e-02, -1.9064e-02,  1.8224e-04,\n",
      "        -7.4013e-02, -1.2157e-02, -1.3567e-03, -6.5173e-02, -2.0954e-01,\n",
      "        -1.4168e-01, -2.7076e-01, -2.4874e-01, -2.5265e-02, -1.2095e-01,\n",
      "        -2.6775e-01, -1.9327e-03, -3.0810e-02, -1.4781e-01, -3.5373e-02,\n",
      "        -7.9340e-02, -7.4338e-03, -1.4769e-01, -9.6493e-02, -2.3959e-01,\n",
      "        -2.0627e-01, -2.0248e-01,  4.5381e-02, -1.0472e-01, -1.2754e-01,\n",
      "        -1.7899e-01, -5.1617e-03, -5.5081e-03, -1.7625e-01, -1.2189e-01,\n",
      "        -5.8592e-02, -8.1587e-03, -8.3833e-02, -2.0714e-02, -1.8470e-01,\n",
      "        -1.2107e-01,  2.7088e-02, -2.7696e-01, -2.1153e-01, -4.6376e-02,\n",
      "        -2.2858e-01, -4.0585e-02, -2.4741e-01, -2.9983e-02, -1.3015e-01,\n",
      "        -2.7734e-01, -2.1459e-01, -2.1597e-01, -1.4904e-03,  4.3939e-02,\n",
      "        -2.0581e-01,  1.3008e-01, -1.2595e-01, -4.4431e-02, -1.0383e-02,\n",
      "        -1.8114e-01, -1.3720e-01, -3.0266e-01, -1.0855e-01, -5.9038e-02,\n",
      "         1.2297e-03, -1.8104e-01,  8.3802e-03,  3.4795e-02,  8.0912e-02,\n",
      "        -3.1507e-02, -2.2049e-02, -6.0942e-02,  2.7446e-02, -6.2641e-02,\n",
      "        -2.3222e-02, -2.6642e-02, -2.9548e-03, -3.5551e-02, -3.9529e-02,\n",
      "        -2.6674e-02, -1.0728e-01, -7.2692e-02,  2.8925e-03, -2.6680e-02,\n",
      "         2.9327e-02, -4.0864e-02, -3.8629e-02, -2.6297e-02, -7.5087e-02,\n",
      "        -2.0085e-01, -1.1831e-02, -2.8238e-02,  1.0246e-01,  1.7003e-02,\n",
      "        -2.3645e-02, -2.4378e-02, -3.7669e-02, -2.1747e-02, -3.2033e-02,\n",
      "         8.9775e-02,  1.3380e-02, -4.0500e-02, -2.3220e-02, -3.6884e-02,\n",
      "        -2.0292e-01, -1.0587e-01, -4.1942e-02, -2.8809e-01, -9.4072e-02,\n",
      "        -9.6567e-03, -9.0437e-02, -1.1249e-02, -1.0710e-01, -3.3320e-02,\n",
      "         3.8646e-02,  2.3373e-02,  4.7254e-02, -1.1220e-01,  6.8284e-02,\n",
      "        -1.4188e-01, -3.4729e-02, -2.0048e-02,  5.0685e-02,  1.9616e-01,\n",
      "        -6.8053e-02,  1.3022e-01, -3.5022e-02, -1.3556e-01, -1.3475e-01,\n",
      "        -2.0847e-02,  6.8572e-02,  1.4251e-02, -2.6545e-02, -1.4651e-01,\n",
      "         6.8531e-02, -1.0746e-01, -9.1881e-02,  4.6730e-03, -5.9786e-02,\n",
      "        -7.6161e-02, -2.3234e-01, -2.6778e-02, -1.7661e-01, -2.1050e-02,\n",
      "         4.1263e-02, -8.7461e-02, -1.3499e-01,  1.3895e-03, -1.9462e-01,\n",
      "        -1.0616e-01, -1.2021e-01, -9.5417e-02, -8.1403e-02,  3.1380e-02,\n",
      "        -2.2520e-01, -1.0435e-01,  1.3297e-01, -1.8943e-01, -9.9817e-02,\n",
      "        -1.5738e-02, -2.2885e-01, -1.3125e-01,  9.4837e-02, -9.0094e-02,\n",
      "        -1.2959e-01,  4.7358e-02, -2.4706e-01, -8.9113e-02, -1.2445e-01,\n",
      "        -6.9565e-02, -1.5359e-01, -1.8016e-01, -1.5810e-02, -2.4073e-01,\n",
      "         1.9250e-02, -1.5055e-01, -4.8312e-03, -2.7661e-02, -1.2859e-01,\n",
      "        -9.9913e-02, -1.5083e-01, -1.3406e-01, -2.0796e-01, -7.4511e-02,\n",
      "        -1.4511e-02, -2.6576e-01, -1.2590e-01, -1.8426e-02, -2.2686e-02,\n",
      "        -1.8781e-02, -1.8800e-02,  6.9495e-02, -2.7995e-02, -2.4231e-01,\n",
      "        -1.3116e-02, -1.1874e-01, -1.4722e-01, -3.2746e-01, -2.7087e-01,\n",
      "        -1.2331e-01, -1.2786e-01, -1.7545e-01, -1.8282e-01, -2.9496e-01,\n",
      "        -1.9556e-02, -1.8946e-01,  1.3346e-01, -1.0568e-01, -1.2394e-01,\n",
      "        -1.0879e-01, -1.6203e-01, -1.8495e-01, -1.6359e-01, -7.3927e-03,\n",
      "        -8.5187e-02, -4.3468e-02,  8.2591e-02, -2.6701e-03, -1.0589e-01,\n",
      "        -5.4097e-02, -4.2530e-02, -3.5932e-02, -7.5661e-02, -3.5025e-02,\n",
      "         4.1097e-02, -1.3118e-01, -1.3827e-01, -4.7558e-02, -1.3692e-02,\n",
      "        -4.4765e-02, -2.3334e-02, -4.5761e-02, -2.8389e-02, -1.5297e-02,\n",
      "        -1.0423e-01, -1.4650e-02,  7.8159e-02, -1.2976e-03, -6.2127e-03,\n",
      "        -8.3344e-02, -2.2789e-02,  5.0938e-02, -3.4075e-03, -1.0655e-02,\n",
      "        -1.3742e-02, -1.9965e-01, -5.5636e-02, -2.1332e-02, -1.7621e-01,\n",
      "         1.4151e-02,  2.2167e-01, -3.4174e-02, -2.6408e-02, -2.0011e-01,\n",
      "        -4.8269e-02, -1.5449e-01, -1.1220e-01, -2.2998e-01, -1.3196e-01,\n",
      "        -1.6346e-01, -1.2492e-01, -2.0280e-02, -2.7501e-02,  6.7035e-02,\n",
      "        -1.0026e-01, -7.5276e-02, -1.0762e-01, -4.3467e-02,  2.5141e-02,\n",
      "        -5.2910e-02, -3.5488e-02, -2.3404e-01, -8.2981e-02, -3.5537e-03,\n",
      "         1.4191e-01, -5.6674e-02, -2.4163e-01, -5.8430e-02, -3.9872e-02,\n",
      "        -1.4567e-01, -1.3689e-01,  8.4235e-02,  1.1690e-01, -1.3384e-01,\n",
      "        -1.1549e-01, -5.4177e-02, -5.0532e-02,  2.2171e-01, -1.7411e-01,\n",
      "        -1.0144e-02, -4.8123e-02, -2.8712e-01,  1.1908e-01, -1.0571e-01,\n",
      "        -1.7144e-01, -8.9135e-02, -1.6033e-01, -7.5774e-02,  1.1471e-01,\n",
      "        -2.4564e-01, -1.6454e-01, -2.4996e-02, -1.8732e-01, -1.8325e-02],\n",
      "       requires_grad=True)\n",
      "Name of the layer:  fc2.weight\n",
      "Parameters:  Parameter containing:\n",
      "tensor([[ 0.2171, -0.0721, -0.0860,  ...,  0.0166,  0.0598,  0.0336],\n",
      "        [-0.0386, -0.0318,  0.0300,  ...,  0.0224, -0.0286,  0.0229],\n",
      "        [-0.2102,  0.2975, -0.0133,  ...,  0.0012, -0.0506, -0.0247],\n",
      "        ...,\n",
      "        [-0.2211,  0.2224, -0.0534,  ..., -0.0151,  0.0066,  0.0315],\n",
      "        [ 0.0112, -0.0250,  0.1002,  ..., -0.0086, -0.0430,  0.0163],\n",
      "        [-0.1259, -0.0153,  0.0603,  ...,  0.0059,  0.0080, -0.0154]],\n",
      "       requires_grad=True)\n",
      "Name of the layer:  fc2.bias\n",
      "Parameters:  Parameter containing:\n",
      "tensor([-0.3516,  0.0231, -0.1709, -0.0614, -0.0885, -0.0476, -0.2129, -0.1324,\n",
      "        -0.2354, -0.0883, -0.0884, -0.1791,  0.0265, -0.2434,  0.0407, -0.0724,\n",
      "        -0.0008, -0.0103,  0.0506, -0.0057, -0.2027, -0.2319, -0.0856,  0.0383,\n",
      "        -0.1970, -0.2551, -0.1369, -0.1542, -0.2240, -0.2758, -0.1195, -0.1818,\n",
      "        -0.0831, -0.1508, -0.1785, -0.2164, -0.1744, -0.1193, -0.2773, -0.1295,\n",
      "        -0.0305, -0.1336, -0.2204, -0.1238, -0.2009, -0.1347, -0.1404, -0.0165,\n",
      "        -0.1296, -0.1335, -0.3421, -0.1163, -0.1005, -0.2022, -0.2090, -0.0660,\n",
      "         0.0162,  0.0715, -0.1475, -0.2246, -0.0992, -0.0959, -0.0624, -0.0503,\n",
      "         0.0140, -0.0106, -0.1088, -0.2814, -0.1753, -0.2196,  0.0571, -0.0907,\n",
      "        -0.2122, -0.2534, -0.0632, -0.0049, -0.1554, -0.2401,  0.0477, -0.0942,\n",
      "        -0.1080, -0.3561, -0.0288, -0.2284, -0.3338, -0.1679,  0.1138,  0.0572,\n",
      "        -0.1951, -0.1444, -0.2890, -0.0249,  0.0314, -0.2631, -0.1355, -0.0657,\n",
      "        -0.0875, -0.1336, -0.0611, -0.2006, -0.1271, -0.1874, -0.0989, -0.1971,\n",
      "        -0.0807, -0.1508,  0.0376, -0.2921, -0.0971, -0.1600, -0.1326, -0.0386,\n",
      "        -0.2260, -0.3090, -0.1615,  0.0249, -0.1300, -0.2339, -0.0577, -0.1171],\n",
      "       requires_grad=True)\n",
      "Name of the layer:  fc3.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:  Parameter containing:\n",
      "tensor([[-0.0081, -0.0715,  0.0574,  ...,  0.0333,  0.0243,  0.0668],\n",
      "        [-0.1221, -0.0394, -0.0789,  ..., -0.1950, -0.2615, -0.2987],\n",
      "        [ 0.0763, -0.0210, -0.0540,  ..., -0.0355, -0.2372, -0.2545],\n",
      "        ...,\n",
      "        [ 0.0553, -0.0249, -0.1454,  ..., -0.0747, -0.1201,  0.0435],\n",
      "        [-0.1644,  0.0262, -0.4809,  ..., -0.0870, -0.0270,  0.0498],\n",
      "        [-0.2888, -0.0394,  0.0748,  ..., -0.2171, -0.0425, -0.1535]],\n",
      "       requires_grad=True)\n",
      "Name of the layer:  fc3.bias\n",
      "Parameters:  Parameter containing:\n",
      "tensor([-0.0438,  0.0788, -0.0590, -0.0231,  0.0767, -0.1086, -0.1369, -0.0259,\n",
      "         0.0564, -0.1384], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, param in Dig_net.named_parameters():\n",
    "    print(\"Name of the layer: \",name)\n",
    "    print(\"Parameters: \",param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HNRHXCKjD7es",
    "outputId": "0edd6264-8aa0-4eaf-aa52-bb93af2e1b36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************* ADAM AS OPTIMIZER && CEL AS LOSS FUNC ********************\n",
      "Accuracy of the network on the 10000 test images: 98 %\n",
      "Accuracy(USING SKLEARN) of the network on the 10000 test images: % 98.09\n"
     ]
    }
   ],
   "source": [
    "#****************************** Adam as OPTIMIZER && Cross Entropy as LOSS Func ********************************\n",
    "\n",
    "# Evaluate model on test set. This is done in the same way as for training but only till calculating output.\n",
    "correct = 0\n",
    "total = 0\n",
    "prediction=[]\n",
    "Actual=[]\n",
    "with torch.no_grad():\n",
    "    for data in Dig_testloader:\n",
    "        images, labels = data\n",
    "        outputs = Dig_net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        prediction.extend(predicted)\n",
    "        Actual.extend(labels)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    " \n",
    "\n",
    " \n",
    "#Then,convert output from tensor to numpy format.\n",
    "# convert to class labels\n",
    "# store the predictions\n",
    "prediction=np.array(prediction)\n",
    "Actual=np.array(Actual)\n",
    "\n",
    "print(\"******************* ADAM AS OPTIMIZER && CEL AS LOSS FUNC ********************\")\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "# calculate accuracy of model\n",
    "print('Accuracy(USING SKLEARN) of the network on the 10000 test images: %' ,100*accuracy_score(Actual,prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "rwmb-Kl1ZpPZ",
    "outputId": "e8d0ae41-a1ff-48a3-814b-0b0b2fa50d9a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:  tensor(7) tensor(2) tensor(1) tensor(0)\n",
      "Predicted:  tensor(7) tensor(2) tensor(1) tensor(0)\n"
     ]
    }
   ],
   "source": [
    "# check predictions by printing the output image for random test inputs.\n",
    "dataiter = iter(Dig_testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % labels[j] for j in range(4)))\n",
    "\n",
    "outputs=Dig_net(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % predicted[j] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>****************** Alphabet Classification ******************</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About Alphabet dataset:<br>\n",
    "Link for the Alphabet dataset is:\n",
    "https://www.kaggle.com/sachinpatel21/az-handwritten-alphabets-in-csv-format?select=A_Z+Handwritten+Data.csv\n",
    "\n",
    "This A-Z Alphabet Dataset consist more than 3 Lakh examples in numerical/pixel form in csv format.\n",
    "This will take a lot of time to train and test. Since the accuracy doesn't matter for this assignment, so\n",
    "I decided to reduce the number of examples to 2600 with each class has 100 examples.\n",
    "\n",
    "So, code to reduce the data:\n",
    "***********************************************\n",
    "<code>\n",
    "data = pd.read_csv(\"A_Z_Handwritten_Data.csv\")\n",
    "data = np.array(data)\n",
    "\n",
    "Mdata=[]\n",
    "for i in range(26):\n",
    "    T=data[data[:,0]==i]\n",
    "    T=T[ np.random.choice( T.shape[0],100, False),:]\n",
    "    Mdata.extend(list(T))\n",
    "\n",
    "Mdata=np.array(Mdata)\n",
    "df=pd.DataFrame(Mdata)\n",
    "df.to_csv(\"Modified_Data.csv\",index=False)\n",
    "</code>\n",
    "\n",
    "************************************************\n",
    "New Modified Data is saved, Link to access the data is:\n",
    "https://docs.google.com/spreadsheets/d/13rkn6KFFe3JkC1DVyh26FiNUNQJxEMqxwKXNwevDXkM/edit?usp=sharing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9P1AaBLYFcv6",
    "outputId": "f625b8b7-bbfa-4e3f-d09c-50106308f572"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Alph_data:  (2600, 786)\n",
      "Input Matrix of Shape:  (2600, 784)\n",
      "True Labels of Shape:  (2600,)\n",
      "X-train :  (1820, 784)\n",
      "Y-train :  (1820,)\n",
      "X-test :  (780, 784)\n",
      "Y-test :  (780,)\n",
      "******* After Reshaping ********\n",
      "X-train :  (1820, 1, 28, 28)\n",
      "Y-train :  (1820,)\n",
      "X-test :  (780, 1, 28, 28)\n",
      "Y-test :  (780,)\n"
     ]
    }
   ],
   "source": [
    "# Loading the main csv file in which first index is the row number \n",
    "# second index is class label, from third image vector of dim 784\n",
    "Alph_data = pd.read_csv(\"Modified.csv\")\n",
    "print(\"Shape of Alph_data: \",Alph_data.shape)\n",
    "\n",
    "# Separating image (in float32 datatype) and label\n",
    "X_Alph = (Alph_data.iloc[:,2:786].values).astype('float32')\n",
    "Y_Alph = (Alph_data.iloc[:,1].values)\n",
    "print(\"Input Matrix of Shape: \",X_Alph.shape)\n",
    "print(\"True Labels of Shape: \",Y_Alph.shape)\n",
    "\n",
    "# separating for train and test data using sklearn\n",
    "X_Alph_train, X_Alph_test, Y_Alph_train, Y_Alph_test = train_test_split(X_Alph,\n",
    "                                        Y_Alph, test_size=0.30, random_state=42)\n",
    "print(\"X-train : \",X_Alph_train.shape)\n",
    "print(\"Y-train : \",Y_Alph_train.shape)\n",
    "print(\"X-test : \",X_Alph_test.shape)\n",
    "print(\"Y-test : \",Y_Alph_test.shape)\n",
    "\n",
    "# reshaping the data as per model requirement\n",
    "X_Alph_train = X_Alph_train.reshape(X_Alph_train.shape[0],1, 28, 28)\n",
    "X_Alph_test = X_Alph_test.reshape(X_Alph_test.shape[0],1, 28, 28)\n",
    "\n",
    "print(\"******* After Reshaping ********\")\n",
    "print(\"X-train : \",X_Alph_train.shape)\n",
    "print(\"Y-train : \",Y_Alph_train.shape)\n",
    "print(\"X-test : \",X_Alph_test.shape)\n",
    "print(\"Y-test : \",Y_Alph_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "id": "8UW1mMfoGNni",
    "outputId": "47f68d21-b61b-43c1-9e9e-99ebd38a710e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train samples\n",
    "for i in range(6, 9):\n",
    "    plt.subplot(330 + (i+1))\n",
    "    plt.imshow(X_Alph_train[i].squeeze(), cmap=plt.get_cmap('gray'))\n",
    "    plt.title(chr(Y_Alph_train[i]+65))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "id": "9F3kY3gLGWW3",
    "outputId": "3e054d68-7703-4297-ae24-4437519aceb8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test samples\n",
    "for i in range(6, 9):\n",
    "    plt.subplot(330 + (i+1))\n",
    "    plt.imshow(X_Alph_test[i].squeeze(), cmap=plt.get_cmap('gray'))\n",
    "    plt.title(chr(Y_Alph_test[i]+65))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "qhx8H7bpGl5-"
   },
   "outputs": [],
   "source": [
    "# Converting the data into Tensor Dataset because everything will be in tensor\n",
    "X_Alph_train_tensor = torch.tensor(X_Alph_train)/255.0\n",
    "Y_Alph_train_tensor = torch.tensor(Y_Alph_train)\n",
    "Alph_train_tensor = torch.utils.data.TensorDataset(X_Alph_train_tensor, Y_Alph_train_tensor)\n",
    "\n",
    "X_Alph_test_tensor = torch.tensor(X_Alph_test)/255.0\n",
    "Y_Alph_test_tensor = torch.tensor(Y_Alph_test)\n",
    "Alph_test_tensor = torch.utils.data.TensorDataset(X_Alph_test_tensor, Y_Alph_test_tensor)\n",
    "\n",
    "# Making Data loader which passes the data while training or any job, in batches\n",
    "Alph_train_loader = torch.utils.data.DataLoader(Alph_train_tensor, batch_size=4, num_workers=2, shuffle=True)\n",
    "Alph_test_loader =torch.utils.data.DataLoader(Alph_test_tensor, batch_size=4, num_workers=2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "TYPhRsh6T7TM"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Class 'Net_for_Alph' which is used to create convolution neural network for \n",
    "classification of Alphabets and it is a sub class which uses its super class \n",
    "namely 'nn.Module' which is provided by torch library.There are following funtions:\n",
    "\n",
    "        1. __init__ : This Function is always required for a class which is used\n",
    "                      to initialise variables. Here, this class first initialised\n",
    "                      variables of its super class.Then, it initialised its own \n",
    "                      variables which are basically layers of convolution neural\n",
    "                      network.\n",
    "                      First Variable is \"conv1\" which is first Convolution layer of \n",
    "                      network which is initialised with inbuilt convolution layer \n",
    "                      provided by torch.nn .This layer will accept the inputs in batches\n",
    "                      with one channel, then it outputs 32 channels with the help of\n",
    "                      kernel of size 3 and padding 1.\n",
    "                      \n",
    "                      Second Variable is \"pool\" which is initialised with Max Pool Layer\n",
    "                      provided by torch.nn with kernel size 2 and stride 2.This layer \n",
    "                      can be used after any layer whenever we want to reduce the dimension.\n",
    "                      \n",
    "                      Third Variable is \"conv2\" which is second Convolution layer of \n",
    "                      network which is initialised with inbuilt convolution layer \n",
    "                      provided by torch.nn .This layer will accept the inputs in batches\n",
    "                      with 32 channel (output by previous layer), then it outputs 64 channels\n",
    "                      with the help of kernel of size 3.\n",
    "                      \n",
    "                      Fourth Variable is \"fc1\" which is first fully connected layer of the neural\n",
    "                      network initialised with help of torch.nn.Linear which is linear layer\n",
    "                      of network.This object takes input of 64*6*6 (This can be decided on \n",
    "                      our own) and it outputs 600 units(decided on our own).\n",
    "                      \n",
    "                      Fifth Variable is \"drop\" which is object of dropout layer which is\n",
    "                      used to prevent the model from overfitting.Layer is provided by \n",
    "                      torch.nn .It takes probability( values getting 0) as input.\n",
    "                      \n",
    "                      Sixth Variable is \"fc2\" which is second fully connected layer of the neural\n",
    "                      network initialised with help of torch.nn.Linear which is linear layer\n",
    "                      of network.This object takes input of 600 ( output from previous layer)\n",
    "                      and it outputs 120 units(decided on our own).\n",
    "                      \n",
    "                      Seventh Variable is \"fc3\" which is last fully connected layer of the neural\n",
    "                      network initialised with help of torch.nn.Linear which is linear layer\n",
    "                      of network.This object takes input of 120 ( output from previous layer)\n",
    "                      and it outputs 26 units(total number of classes).\n",
    "                      \n",
    "        2. forward: This Function is used to forward propagate in the neural network which is\n",
    "                    called by it super class.This function is provided by the input that we are\n",
    "                    going to feed in the neural network.\n",
    "                    Flow of the network:\n",
    "                    1.Feeded to convolution layer 1\n",
    "                    2.Passed through ReLU Layer (Activation Layer)\n",
    "                    3.Passed through Max Pooling Layer\n",
    "                    4.Feeded to convolution layer 2\n",
    "                    5.Passed through ReLU Layer (Activation Layer)\n",
    "                    6.Passed through Max Pooling Layer\n",
    "                    \n",
    "                    Squeezed all values to one dimension so that it can be feeded in Linear Layer\n",
    "                    \n",
    "                    7.Passed through Fully Connected Layer 1\n",
    "                    8.Passed through ReLU Layer(Activation Layer)\n",
    "                    9.Passed through Dropout Layer\n",
    "                    10.Passed through Fully Connected Layer 2\n",
    "                    11.Passed through ReLU Layer(Activation Layer)\n",
    "                    12.Passed through Last Fully connected layer.\n",
    "                    \n",
    "                    Last Layer give the pobabilty of the classes from which answer will be the \n",
    "                    class which has max probability.\n",
    "                    This value is returned by this function.\n",
    "                    \n",
    "'''\n",
    "class Net_for_Alph(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_for_Alph, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(in_features=64*6*6, out_features=600)\n",
    "        self.drop = nn.Dropout2d(0.25)\n",
    "        self.fc2 = nn.Linear(in_features=600, out_features=120)\n",
    "        self.fc3 = nn.Linear(in_features=120, out_features=26)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FdGdw9i8ESwx",
    "outputId": "8178bcc3-18d8-4a66-95e4-ba4f3c8c5fd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   400] CELloss: 0.428\n",
      "[2,   400] CELloss: 0.136\n",
      "[3,   400] CELloss: 0.076\n",
      "[4,   400] CELloss: 0.054\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#******************************ADAM as OPTIMIZER && CROSS ENTROPY as LOSS Func********************************\n",
    "\n",
    "# Define training the model\n",
    "Alph_net = Net_for_Alph()\n",
    "\n",
    "# defining the optimizer\n",
    "optimizer = optim.Adam(Alph_net.parameters(), lr=0.001)\n",
    "\n",
    "# defining the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# For each epoch and in each batch:\n",
    "for epoch in range(4):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(Alph_train_loader,0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs,labels = data\n",
    "        \n",
    "        # clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # compute the model output\n",
    "        outputs = Alph_net(inputs)\n",
    "        \n",
    "        # calculate loss\n",
    "        CELloss = criterion(outputs, labels)\n",
    "        \n",
    "        # propagate loss backwards\n",
    "        CELloss.backward()\n",
    "        \n",
    "        # update model weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += CELloss.item()\n",
    "        if i % 400 == 399:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] CELloss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "S1xV6z7fa9_y"
   },
   "outputs": [],
   "source": [
    "#Saving the trained model in the PATH\n",
    "PATH = './Adam_CEL_Alph_net_ep4.pth'\n",
    "torch.save(Alph_net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing back the learnt parameters\n",
    "PATH = './Adam_CEL_Alph_net_ep4.pth'\n",
    "Alph_net = Net_for_Alph()\n",
    "Alph_net.load_state_dict(torch.load(PATH)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learnt Weights and bias for each layer of Convolution Neural Network Alph_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of the layer:  conv1.weight\n",
      "Parameters:  Parameter containing:\n",
      "tensor([[[[-0.0915, -0.1051, -0.2436],\n",
      "          [-0.2733, -0.0032, -0.5558],\n",
      "          [-0.1288, -0.3738, -0.3073]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0208,  0.3287, -0.3558],\n",
      "          [ 0.1354,  0.1151, -0.4295],\n",
      "          [ 0.2860, -0.2505, -0.3308]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3757, -0.0143, -0.3686],\n",
      "          [ 0.2583, -0.2774, -0.2772],\n",
      "          [ 0.0751, -0.2084,  0.0102]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3413, -0.3350, -0.3071],\n",
      "          [ 0.0870, -0.2873, -0.0834],\n",
      "          [ 0.0090, -0.3139,  0.3898]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0874,  0.4303,  0.1620],\n",
      "          [-0.1562, -0.2010,  0.3138],\n",
      "          [-0.3397, -0.1226,  0.2268]]],\n",
      "\n",
      "\n",
      "        [[[-0.3204,  0.2270,  0.3923],\n",
      "          [-0.2203,  0.2751, -0.1671],\n",
      "          [ 0.0946,  0.0619, -0.0473]]],\n",
      "\n",
      "\n",
      "        [[[-0.0351,  0.2256,  0.3293],\n",
      "          [-0.0782,  0.1565, -0.3639],\n",
      "          [ 0.1032, -0.0059, -0.4917]]],\n",
      "\n",
      "\n",
      "        [[[-0.1105, -0.3346, -0.1819],\n",
      "          [ 0.3642,  0.3834,  0.0166],\n",
      "          [-0.1925,  0.2877,  0.4544]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0433,  0.1963,  0.3049],\n",
      "          [-0.0797,  0.1383, -0.2396],\n",
      "          [ 0.0621,  0.0465,  0.2826]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1227,  0.4360,  0.3377],\n",
      "          [ 0.4021,  0.0858,  0.2981],\n",
      "          [-0.1584,  0.2977, -0.2518]]],\n",
      "\n",
      "\n",
      "        [[[-0.0089,  0.3081, -0.3352],\n",
      "          [ 0.3095,  0.3407,  0.2178],\n",
      "          [ 0.1575, -0.1188,  0.1774]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4746,  0.2807, -0.1626],\n",
      "          [-0.1987, -0.1751,  0.0021],\n",
      "          [-0.3744, -0.1968, -0.4245]]],\n",
      "\n",
      "\n",
      "        [[[-0.3058, -0.1011,  0.3421],\n",
      "          [-0.2900,  0.0353,  0.0806],\n",
      "          [-0.2712,  0.0351,  0.2504]]],\n",
      "\n",
      "\n",
      "        [[[-0.1004,  0.0614,  0.1701],\n",
      "          [-0.2547, -0.0068,  0.4129],\n",
      "          [-0.3201, -0.0270,  0.2896]]],\n",
      "\n",
      "\n",
      "        [[[-0.0420, -0.3608, -0.1669],\n",
      "          [-0.2649, -0.3012, -0.2670],\n",
      "          [ 0.3091,  0.3909,  0.4417]]],\n",
      "\n",
      "\n",
      "        [[[-0.3126,  0.0320, -0.1253],\n",
      "          [-0.1953,  0.0405, -0.1637],\n",
      "          [-0.0043, -0.2266, -0.1568]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0290,  0.0629,  0.3824],\n",
      "          [ 0.0092, -0.2115, -0.2925],\n",
      "          [-0.3609, -0.2442, -0.1254]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2705,  0.2334,  0.1486],\n",
      "          [-0.2988,  0.1906, -0.2805],\n",
      "          [-0.1205,  0.1613,  0.1677]]],\n",
      "\n",
      "\n",
      "        [[[-0.1899, -0.0690,  0.0453],\n",
      "          [ 0.2789, -0.2936, -0.2788],\n",
      "          [ 0.2644, -0.3476, -0.2881]]],\n",
      "\n",
      "\n",
      "        [[[-0.0863,  0.1056, -0.2797],\n",
      "          [ 0.2419,  0.3405,  0.4125],\n",
      "          [ 0.0393,  0.0726, -0.0536]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3004,  0.0133,  0.1609],\n",
      "          [ 0.2893,  0.0595, -0.2917],\n",
      "          [ 0.2506, -0.1041, -0.2830]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1192, -0.1396, -0.0768],\n",
      "          [ 0.2107,  0.4020,  0.3044],\n",
      "          [-0.1616,  0.2269,  0.1301]]],\n",
      "\n",
      "\n",
      "        [[[-0.3301, -0.1832, -0.0402],\n",
      "          [-0.2129,  0.2654, -0.0413],\n",
      "          [ 0.0359, -0.3031,  0.0237]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1567, -0.1690, -0.2755],\n",
      "          [-0.3032, -0.3246,  0.2579],\n",
      "          [-0.0703,  0.1947,  0.0527]]],\n",
      "\n",
      "\n",
      "        [[[-0.3191, -0.1343, -0.0954],\n",
      "          [-0.1543, -0.0618, -0.2093],\n",
      "          [-0.2615, -0.0165,  0.2300]]],\n",
      "\n",
      "\n",
      "        [[[-0.0789,  0.4149,  0.5216],\n",
      "          [-0.2170, -0.1792, -0.1873],\n",
      "          [-0.0041, -0.5295, -0.0011]]],\n",
      "\n",
      "\n",
      "        [[[-0.4441, -0.3925,  0.0149],\n",
      "          [ 0.1880, -0.0134, -0.2368],\n",
      "          [ 0.2704, -0.1761,  0.0733]]],\n",
      "\n",
      "\n",
      "        [[[-0.0387, -0.1227,  0.1403],\n",
      "          [-0.0472,  0.1332, -0.1034],\n",
      "          [-0.0914, -0.2115, -0.1996]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2454,  0.4531,  0.0287],\n",
      "          [-0.1267,  0.3658,  0.1062],\n",
      "          [ 0.1062, -0.2599,  0.0725]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1530, -0.2768, -0.2657],\n",
      "          [-0.1722,  0.1623, -0.2254],\n",
      "          [ 0.3885,  0.0168,  0.3073]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2074, -0.3814, -0.1939],\n",
      "          [ 0.2357,  0.1002,  0.1839],\n",
      "          [-0.1516,  0.3285, -0.0105]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2748,  0.1855, -0.3422],\n",
      "          [-0.1076,  0.3376,  0.1506],\n",
      "          [-0.2257,  0.1248, -0.0550]]]], requires_grad=True)\n",
      "Name of the layer:  conv1.bias\n",
      "Parameters:  Parameter containing:\n",
      "tensor([ 0.3708,  0.1682,  0.0153,  0.0773, -0.0053, -0.0157,  0.0701, -0.1476,\n",
      "         0.0566, -0.2535, -0.0440,  0.0193,  0.0303, -0.1393,  0.1426, -0.1119,\n",
      "         0.2131, -0.0207,  0.1519, -0.0402, -0.1768, -0.1162, -0.2234,  0.1183,\n",
      "        -0.2308,  0.0535,  0.0837, -0.2726, -0.0400, -0.0070, -0.0224, -0.1123],\n",
      "       requires_grad=True)\n",
      "Name of the layer:  conv2.weight\n",
      "Parameters:  Parameter containing:\n",
      "tensor([[[[-5.8174e-02, -2.5699e-02, -5.3006e-04],\n",
      "          [-1.7816e-01,  8.8037e-04,  3.8079e-02],\n",
      "          [-4.8261e-02, -3.4960e-02, -4.5278e-02]],\n",
      "\n",
      "         [[-4.5569e-02, -2.6545e-02, -4.5031e-02],\n",
      "          [ 1.0768e-01, -3.6066e-02,  4.0309e-04],\n",
      "          [ 9.9604e-02, -3.5381e-02, -5.7573e-02]],\n",
      "\n",
      "         [[-1.8749e-02, -8.7208e-02, -5.8392e-03],\n",
      "          [ 3.9941e-02,  1.0019e-01,  3.1492e-02],\n",
      "          [ 1.6861e-02,  6.9567e-02, -9.3491e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.8167e-02, -8.0344e-02,  1.9492e-03],\n",
      "          [-3.4904e-02, -8.7457e-03, -8.7926e-02],\n",
      "          [-3.4440e-03,  4.8556e-02, -9.8815e-02]],\n",
      "\n",
      "         [[ 3.9278e-02, -7.6976e-02, -1.8225e-02],\n",
      "          [ 6.0220e-02,  6.1559e-05, -5.6333e-02],\n",
      "          [ 2.1351e-02,  2.5869e-02, -3.3756e-02]],\n",
      "\n",
      "         [[-2.3189e-02, -4.3251e-02,  1.1475e-01],\n",
      "          [ 7.0471e-02, -4.6094e-02, -4.8397e-02],\n",
      "          [-2.7917e-03, -6.0242e-02, -2.2364e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9776e-02, -3.8727e-02,  7.1561e-02],\n",
      "          [ 1.8575e-02, -1.5779e-02,  7.2820e-02],\n",
      "          [-2.1203e-01, -2.0499e-01,  3.0180e-02]],\n",
      "\n",
      "         [[-3.4130e-02, -2.1256e-02, -4.5791e-02],\n",
      "          [-1.1358e-01,  2.4948e-02,  1.8083e-02],\n",
      "          [-5.9327e-02,  6.0665e-02,  3.6782e-02]],\n",
      "\n",
      "         [[-1.4260e-01, -3.7972e-02, -1.7482e-02],\n",
      "          [-1.3008e-01, -1.3354e-01, -9.6742e-02],\n",
      "          [ 9.7220e-02,  9.3106e-02,  1.2987e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6214e-01, -1.3971e-01, -8.3263e-02],\n",
      "          [ 9.8094e-02,  1.9512e-01,  3.0409e-02],\n",
      "          [ 3.3604e-02,  2.1564e-01,  1.4756e-01]],\n",
      "\n",
      "         [[-1.2148e-01, -1.0500e-01, -1.5534e-01],\n",
      "          [ 6.7732e-02,  8.2012e-02, -5.7622e-02],\n",
      "          [ 1.8134e-02,  1.2043e-01,  6.7616e-02]],\n",
      "\n",
      "         [[-2.2011e-01,  2.5904e-02, -3.2715e-02],\n",
      "          [-9.4764e-02, -9.5939e-02, -1.4651e-01],\n",
      "          [ 1.1858e-01,  1.3589e-01,  5.7542e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.7102e-02,  6.4989e-02,  1.4226e-02],\n",
      "          [-1.0302e-01, -3.2209e-02,  3.9523e-02],\n",
      "          [-1.1302e-02, -4.9585e-02,  4.6168e-02]],\n",
      "\n",
      "         [[ 2.4366e-02,  3.9580e-02, -5.0646e-02],\n",
      "          [ 4.9916e-02,  2.6455e-02, -4.2330e-02],\n",
      "          [ 5.8373e-02,  1.3380e-01,  5.2700e-02]],\n",
      "\n",
      "         [[ 1.0679e-02,  8.4734e-02, -2.5118e-02],\n",
      "          [ 2.8201e-02,  6.2240e-02,  3.6125e-02],\n",
      "          [-3.6879e-02,  1.5530e-01,  9.2977e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.4825e-02,  1.0652e-02, -7.2336e-02],\n",
      "          [-5.1699e-02,  1.9971e-02, -9.3634e-02],\n",
      "          [-6.5886e-02,  8.1573e-02,  2.2578e-02]],\n",
      "\n",
      "         [[ 4.8732e-02,  5.5252e-02, -8.2860e-02],\n",
      "          [-2.7583e-02,  5.7842e-02, -6.5759e-02],\n",
      "          [ 2.8949e-03,  9.7037e-02,  2.2308e-02]],\n",
      "\n",
      "         [[ 6.5382e-02,  6.0032e-02, -8.2657e-02],\n",
      "          [ 4.2243e-02,  3.5667e-03, -1.6242e-01],\n",
      "          [ 3.0445e-02,  9.0387e-02, -9.8079e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.4978e-01,  1.3442e-02,  1.4322e-02],\n",
      "          [-6.6068e-02, -5.8036e-03,  6.4101e-03],\n",
      "          [ 6.6457e-02,  2.4301e-02,  3.0407e-02]],\n",
      "\n",
      "         [[ 7.7177e-02,  2.4204e-02, -8.0891e-02],\n",
      "          [ 1.1722e-01,  2.4359e-02, -1.8229e-02],\n",
      "          [ 3.9176e-02, -5.3612e-02, -5.3751e-02]],\n",
      "\n",
      "         [[ 5.9183e-02,  1.3949e-01, -3.0594e-02],\n",
      "          [ 1.5139e-01,  1.5070e-02, -5.4210e-02],\n",
      "          [ 1.4222e-01, -7.5202e-03, -4.4074e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.2311e-02,  1.0003e-02, -4.7534e-02],\n",
      "          [ 3.2310e-02, -4.5091e-02, -9.4116e-02],\n",
      "          [ 6.0213e-03, -1.4354e-01, -1.6705e-01]],\n",
      "\n",
      "         [[-5.5341e-02,  1.2890e-02, -4.5267e-02],\n",
      "          [ 4.1902e-02,  3.8083e-03, -4.7753e-02],\n",
      "          [-4.9764e-02, -1.2270e-01, -8.2495e-02]],\n",
      "\n",
      "         [[ 6.4178e-02,  3.0632e-02, -9.8118e-02],\n",
      "          [ 4.1853e-02, -7.9077e-02, -6.8222e-02],\n",
      "          [-2.7439e-02, -8.2213e-02, -3.7945e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1191e-02, -5.4457e-02, -1.4976e-02],\n",
      "          [-3.9338e-02,  2.1451e-03, -2.0325e-02],\n",
      "          [ 3.7639e-02, -2.9359e-02,  4.8043e-02]],\n",
      "\n",
      "         [[-5.6871e-02,  2.7593e-02,  1.2138e-02],\n",
      "          [ 9.5379e-03, -1.0296e-02, -6.5617e-02],\n",
      "          [-4.5370e-02, -4.5928e-02,  6.3786e-03]],\n",
      "\n",
      "         [[-2.2605e-02,  4.0192e-02,  4.8212e-02],\n",
      "          [-1.8951e-02, -1.6656e-02,  2.1503e-02],\n",
      "          [-4.3103e-02, -6.1932e-03,  2.0247e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.4706e-02,  2.7593e-02, -6.1286e-02],\n",
      "          [ 4.2944e-02, -3.4400e-02, -5.3449e-02],\n",
      "          [-2.6730e-02,  3.8417e-02,  8.9788e-04]],\n",
      "\n",
      "         [[-3.6586e-03,  1.0828e-02,  1.9857e-02],\n",
      "          [-3.1357e-02,  1.2657e-02, -6.2417e-02],\n",
      "          [ 4.6903e-02,  1.3334e-02, -7.2995e-03]],\n",
      "\n",
      "         [[-1.0823e-02,  5.6697e-03, -4.9171e-03],\n",
      "          [ 1.1268e-03,  9.3518e-03, -6.0562e-02],\n",
      "          [ 5.1236e-02, -4.3674e-02, -4.2810e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3088e-01, -1.1750e-01, -3.7955e-03],\n",
      "          [-1.3957e-02, -1.5003e-01, -6.6036e-02],\n",
      "          [ 3.1403e-02, -1.6901e-01, -1.2120e-01]],\n",
      "\n",
      "         [[ 7.1364e-03,  6.2986e-02, -8.2557e-03],\n",
      "          [ 2.6460e-03,  2.9269e-02, -2.9022e-02],\n",
      "          [ 3.5144e-02, -7.0233e-02,  5.0146e-02]],\n",
      "\n",
      "         [[ 3.2125e-02,  4.9754e-02,  1.1520e-01],\n",
      "          [ 1.6036e-01, -7.7877e-02, -3.3885e-03],\n",
      "          [ 1.0049e-01, -2.2716e-02, -6.7562e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.9422e-02,  3.1660e-02,  9.9814e-02],\n",
      "          [-1.1631e-01,  7.9120e-03,  1.5104e-01],\n",
      "          [ 4.4185e-02, -2.6694e-02,  3.2955e-02]],\n",
      "\n",
      "         [[-2.5925e-02,  5.9316e-02,  2.1039e-02],\n",
      "          [-9.0863e-02,  2.4010e-02,  1.2057e-01],\n",
      "          [-3.5223e-02, -7.1830e-03,  9.2594e-02]],\n",
      "\n",
      "         [[ 1.0145e-01,  1.4032e-01,  3.3838e-03],\n",
      "          [-1.1021e-01,  1.1445e-01,  7.2308e-02],\n",
      "          [-1.7332e-01,  1.0125e-01,  3.5734e-02]]]], requires_grad=True)\n",
      "Name of the layer:  conv2.bias\n",
      "Parameters:  Parameter containing:\n",
      "tensor([-0.0776, -0.0366, -0.0174,  0.0332, -0.0061,  0.0340, -0.0085, -0.0041,\n",
      "         0.0117, -0.0178, -0.0019, -0.0250,  0.0351,  0.0117, -0.0770, -0.0311,\n",
      "         0.0066, -0.0551,  0.0019, -0.0608,  0.0137, -0.0323, -0.0670, -0.0498,\n",
      "        -0.0067, -0.0668, -0.0155, -0.0446, -0.0400, -0.0463, -0.0382, -0.0121,\n",
      "        -0.0625, -0.0151,  0.0370, -0.0559, -0.0500, -0.0577, -0.0294, -0.0311,\n",
      "         0.0105,  0.0435, -0.0596,  0.0329,  0.0079, -0.0522, -0.0697, -0.0573,\n",
      "        -0.0109, -0.0742, -0.0055, -0.0270, -0.0222,  0.0292, -0.0095,  0.0345,\n",
      "         0.0279, -0.0163, -0.0069,  0.0353, -0.0004, -0.0030,  0.0118, -0.0434],\n",
      "       requires_grad=True)\n",
      "Name of the layer:  fc1.weight\n",
      "Parameters:  Parameter containing:\n",
      "tensor([[ 0.0059,  0.0241,  0.0282,  ...,  0.0240, -0.0392, -0.0041],\n",
      "        [ 0.0046, -0.0198, -0.0208,  ..., -0.0236, -0.0133, -0.0178],\n",
      "        [-0.0128, -0.0015,  0.0205,  ...,  0.0127,  0.0142, -0.0196],\n",
      "        ...,\n",
      "        [-0.0123,  0.0068,  0.0174,  ..., -0.0087,  0.0032, -0.0134],\n",
      "        [ 0.0088, -0.0136, -0.0156,  ..., -0.0107,  0.0181, -0.0103],\n",
      "        [-0.0084,  0.0013,  0.0042,  ...,  0.0107,  0.0080,  0.0179]],\n",
      "       requires_grad=True)\n",
      "Name of the layer:  fc1.bias\n",
      "Parameters:  Parameter containing:\n",
      "tensor([ 6.7716e-03,  4.8130e-03, -1.6093e-02,  1.4419e-02,  1.2468e-03,\n",
      "        -1.8627e-02, -1.5277e-02,  1.1360e-02, -3.7297e-02,  2.2414e-02,\n",
      "         7.8260e-03, -2.1099e-02,  5.4528e-03,  2.8059e-03, -5.6356e-04,\n",
      "         3.8216e-03, -3.2788e-02,  7.7475e-03, -4.3566e-04, -1.4830e-02,\n",
      "        -2.4498e-02, -2.6653e-02,  2.6733e-03, -2.0604e-02, -7.3435e-03,\n",
      "         5.9139e-03,  2.6671e-02, -9.6406e-03, -6.3567e-02, -5.8584e-03,\n",
      "        -2.1248e-02, -5.5380e-02,  4.1205e-02,  1.6191e-02, -2.4321e-02,\n",
      "         5.9465e-03,  5.1101e-02,  4.7236e-03, -6.9840e-03, -2.3759e-02,\n",
      "         3.8790e-02, -2.5873e-02,  2.2025e-02, -2.3215e-02,  1.4004e-02,\n",
      "        -3.2755e-02, -3.5651e-02,  5.1514e-03,  7.4933e-03,  1.4651e-02,\n",
      "        -2.8545e-02, -2.4701e-02,  8.4513e-03, -1.9062e-02,  4.6386e-03,\n",
      "        -6.5105e-03,  1.8756e-02,  1.7714e-02,  6.6363e-03, -6.6981e-03,\n",
      "        -9.5869e-03, -1.9983e-03,  2.7933e-02,  1.6369e-03, -2.1461e-02,\n",
      "        -5.7287e-05,  2.1631e-02,  1.3123e-02, -2.5555e-02, -3.1023e-02,\n",
      "         2.5631e-03, -2.0187e-03, -2.0637e-02,  7.2299e-03, -1.1018e-03,\n",
      "        -1.6788e-02, -2.3380e-02, -1.1029e-02, -2.2541e-02, -1.1744e-03,\n",
      "        -1.1852e-02, -1.8579e-02, -1.1595e-02, -1.9099e-02, -2.2229e-02,\n",
      "        -1.9545e-02, -5.6992e-03,  6.4846e-03, -5.1339e-03, -2.0668e-02,\n",
      "        -3.5046e-02, -9.6048e-03,  6.1738e-03, -2.1366e-02, -2.0556e-02,\n",
      "        -1.9689e-02, -5.8492e-03, -9.0292e-04,  9.6455e-03,  2.5167e-02,\n",
      "        -7.2986e-04,  2.3460e-02,  1.6062e-03, -1.9033e-02, -1.4128e-02,\n",
      "         1.2470e-02,  5.8108e-03,  4.5468e-02, -4.6533e-03,  5.8753e-03,\n",
      "         6.8398e-03,  8.3381e-03,  1.4884e-02,  8.0161e-03, -4.3733e-02,\n",
      "        -2.6595e-02, -7.6598e-03, -3.7585e-03,  1.2908e-02, -4.8221e-02,\n",
      "        -2.4618e-02,  5.5938e-02,  2.7977e-03, -1.4049e-02, -2.4740e-02,\n",
      "        -1.4066e-02, -1.0131e-02,  6.1402e-03, -1.1097e-02, -1.7203e-02,\n",
      "        -3.0074e-03, -3.2279e-02,  1.9995e-03, -2.1973e-02,  2.3691e-02,\n",
      "        -1.4050e-02, -2.1260e-02,  1.0043e-02, -1.3024e-02,  3.9556e-02,\n",
      "         2.6648e-03,  4.2589e-02, -8.0932e-03, -1.8133e-02, -4.4046e-02,\n",
      "        -5.7942e-02, -3.9700e-03, -5.5920e-03, -2.4871e-02,  1.4133e-02,\n",
      "        -1.0655e-02,  3.9048e-03,  6.6135e-03, -3.1200e-02,  1.1960e-02,\n",
      "         3.9295e-03,  4.0146e-03, -4.9008e-03,  7.2808e-03, -1.1362e-02,\n",
      "         3.6473e-03, -2.3881e-03, -3.8759e-03,  3.4527e-02,  1.1577e-02,\n",
      "        -2.1706e-02,  2.1433e-04,  1.4970e-02,  4.3071e-05, -1.5325e-02,\n",
      "         1.3267e-02, -2.2822e-02, -2.3688e-02, -2.3079e-02,  2.3946e-02,\n",
      "        -6.1675e-03, -2.0793e-02,  2.4512e-04, -3.5029e-02, -2.7252e-02,\n",
      "        -8.0718e-04, -1.9520e-02,  2.4343e-03,  1.0064e-02, -2.6064e-02,\n",
      "        -3.7655e-03, -2.1939e-02,  9.3384e-03,  9.7789e-03, -3.2111e-02,\n",
      "        -1.3615e-02, -2.1333e-02, -1.9757e-02,  3.9446e-03,  3.6557e-03,\n",
      "        -3.6548e-03,  1.2687e-02, -1.3789e-02,  5.0402e-04, -4.7325e-02,\n",
      "        -4.3037e-03,  1.6548e-03, -1.9386e-02, -2.0364e-02, -1.1866e-02,\n",
      "        -2.8649e-02, -2.6098e-02, -1.4690e-02, -2.6520e-02, -2.4513e-02,\n",
      "         1.5261e-02, -2.1735e-02, -2.1000e-02,  1.2282e-02,  2.5006e-02,\n",
      "         4.2455e-03, -1.4436e-03,  6.9829e-04,  2.1518e-03,  1.3636e-02,\n",
      "         3.9769e-02, -2.5799e-02, -2.1458e-02,  9.0699e-03, -8.1811e-03,\n",
      "         7.8003e-03, -1.2308e-02, -3.3061e-02,  4.3745e-03, -2.1726e-02,\n",
      "         1.3804e-03, -2.1178e-03,  3.2962e-02, -1.4301e-02,  1.0726e-02,\n",
      "         1.2579e-02, -2.5050e-02,  6.8038e-03, -1.9292e-02,  7.9738e-03,\n",
      "        -5.2572e-02, -8.2034e-03, -1.9602e-02, -3.6185e-03,  3.6447e-02,\n",
      "        -3.6129e-02, -1.3294e-02, -2.0026e-03, -2.5868e-02,  1.3622e-02,\n",
      "         3.1099e-03,  1.0409e-02, -2.2550e-02, -5.3384e-03, -2.5577e-02,\n",
      "         1.1372e-02, -1.9179e-02, -1.4114e-02, -1.2910e-02,  5.2669e-03,\n",
      "        -1.0709e-02, -1.5965e-02, -2.2845e-02, -1.9265e-02, -1.2570e-02,\n",
      "         1.4634e-02, -6.4961e-03, -1.7617e-04,  2.1111e-02,  1.6753e-03,\n",
      "        -1.4480e-02,  2.6629e-02, -1.3755e-02, -1.5003e-02, -2.0920e-02,\n",
      "        -2.3129e-02, -6.3009e-03, -2.1679e-02,  4.4033e-03, -1.8121e-03,\n",
      "         1.2009e-02, -2.5474e-02, -1.2595e-02,  9.4201e-03,  3.8974e-02,\n",
      "        -3.1414e-02, -9.7434e-03,  5.9280e-03, -8.6423e-03,  1.4446e-02,\n",
      "        -2.0537e-02,  4.3168e-03, -7.0101e-03, -5.0135e-03,  2.9818e-02,\n",
      "        -1.6385e-02,  3.7085e-02, -5.4603e-02,  6.4254e-03, -1.0853e-02,\n",
      "        -2.6774e-02, -5.0500e-03,  2.9040e-03, -6.2619e-03,  2.0178e-03,\n",
      "        -5.0912e-02, -2.0391e-03, -1.2382e-03, -1.4582e-02, -1.8101e-02,\n",
      "        -4.4397e-03, -2.9603e-03,  7.2996e-03,  6.7573e-03,  1.2179e-02,\n",
      "         2.8168e-02, -1.5044e-02, -2.4456e-02, -3.6733e-02,  2.1445e-03,\n",
      "        -2.2749e-02,  2.4413e-02, -1.2743e-02, -1.4303e-03, -2.1247e-02,\n",
      "         1.0207e-02, -1.7840e-02,  1.4520e-03,  1.2341e-02, -1.6349e-03,\n",
      "        -5.0188e-03,  1.2309e-02, -6.1432e-04,  8.8262e-03,  8.3811e-03,\n",
      "        -2.5617e-04, -3.3541e-02,  3.1304e-03,  4.1156e-02, -2.7890e-02,\n",
      "        -2.2568e-02, -1.8549e-02,  4.7715e-03, -5.4936e-03, -3.0148e-02,\n",
      "        -4.5628e-04, -1.0545e-02,  5.8680e-03, -7.5746e-03,  2.1892e-03,\n",
      "        -2.2027e-02, -1.9143e-02, -1.1922e-02, -9.9584e-03, -5.4045e-03,\n",
      "        -1.6855e-02, -1.0506e-02,  6.9431e-03, -2.5122e-02,  2.2179e-03,\n",
      "        -3.5247e-02,  3.4195e-03,  1.9703e-02, -2.5979e-02, -5.0474e-02,\n",
      "         7.1002e-03, -1.7434e-02, -9.4208e-03, -1.7233e-03, -1.7470e-03,\n",
      "        -6.3074e-03,  3.2657e-03,  2.3120e-02, -1.1465e-02, -2.3187e-02,\n",
      "        -6.2636e-03,  6.5987e-03, -3.5697e-02,  9.9962e-03, -1.3214e-02,\n",
      "         1.0959e-02,  1.0903e-02, -3.6453e-05, -2.4911e-02, -1.8597e-02,\n",
      "         3.3386e-02, -8.1180e-03,  1.5002e-03, -5.8366e-03,  2.0268e-03,\n",
      "        -2.3475e-02,  3.7368e-03, -7.5553e-03, -5.0526e-02, -1.5468e-02,\n",
      "        -2.7607e-02, -2.1042e-02, -3.5294e-03, -2.4621e-02,  1.7595e-02,\n",
      "        -1.0330e-02, -2.5312e-02,  1.2869e-02,  4.0759e-03,  5.1441e-03,\n",
      "         1.1801e-02,  6.6187e-03, -1.3799e-03, -5.2172e-03, -1.9253e-02,\n",
      "         5.5707e-03,  1.2155e-02, -1.0636e-02, -6.8769e-03,  1.1888e-02,\n",
      "        -2.1704e-02, -5.6596e-02, -3.1565e-02,  1.2719e-02, -2.8617e-02,\n",
      "         4.6891e-03,  3.3199e-02,  1.0210e-02, -1.3801e-02, -2.7274e-02,\n",
      "        -8.3141e-04,  2.7754e-02,  4.2079e-02, -1.7122e-02,  3.3380e-04,\n",
      "        -2.5932e-02,  9.6644e-06, -4.7046e-03,  1.1950e-02, -5.5236e-03,\n",
      "        -3.9976e-02, -4.8327e-02, -9.8727e-04,  7.2609e-03, -7.7621e-03,\n",
      "         1.3126e-04, -1.0519e-02, -3.5650e-04,  1.5957e-02,  6.3328e-05,\n",
      "         1.8324e-03,  9.3179e-03, -1.7197e-02, -5.2459e-03, -1.8774e-02,\n",
      "         2.1885e-02,  3.2377e-03, -4.5798e-02, -1.2193e-02,  5.8852e-03,\n",
      "        -3.8308e-02, -6.7492e-03,  3.7785e-03, -5.1102e-03,  5.2527e-04,\n",
      "         1.0930e-02, -1.6628e-04, -3.3019e-02,  4.1165e-02,  3.6283e-02,\n",
      "        -2.1644e-02,  1.6097e-02, -1.1942e-02,  8.9929e-04, -6.5774e-03,\n",
      "         8.7439e-03, -2.5273e-02, -1.6153e-02,  4.7347e-02, -1.7297e-02,\n",
      "         8.3331e-03,  5.3276e-03,  3.9414e-03,  4.2185e-03, -1.7299e-03,\n",
      "        -2.0611e-02, -2.5485e-03, -2.1080e-02, -5.7396e-03, -3.9556e-02,\n",
      "        -5.4313e-03, -1.2651e-02, -1.3883e-02, -6.6019e-03, -6.6044e-03,\n",
      "        -2.8911e-02, -1.0831e-02,  1.8441e-02, -1.7797e-02, -9.5971e-03,\n",
      "         3.3131e-02, -2.1219e-02, -2.3973e-03,  9.1271e-03,  2.3669e-03,\n",
      "        -3.6773e-02, -7.8844e-03, -7.9113e-03, -2.6892e-02, -4.5044e-02,\n",
      "         4.5727e-04, -2.1346e-02,  1.0555e-02, -1.8601e-02,  8.9019e-03,\n",
      "         3.3744e-02,  3.9892e-02,  3.0581e-02,  1.0382e-02,  5.5192e-03,\n",
      "        -1.2320e-03, -1.3371e-02, -1.6643e-02,  1.2859e-02, -3.6569e-02,\n",
      "        -2.4541e-02,  1.4086e-02,  2.1738e-02, -4.6193e-02, -1.9172e-02,\n",
      "         2.0742e-02,  2.1794e-02, -2.0231e-03, -3.1515e-02, -9.3172e-03,\n",
      "        -6.5310e-03, -2.1489e-02, -2.4317e-02, -2.0114e-02, -2.2564e-02,\n",
      "        -7.8969e-03, -1.9354e-03,  1.1499e-02, -5.4418e-03, -3.0361e-02,\n",
      "        -1.0063e-02, -9.0933e-03, -2.8807e-03, -2.2240e-02, -1.0265e-02,\n",
      "        -6.9334e-04, -2.0336e-02, -1.9347e-02,  3.6979e-02, -2.2862e-02,\n",
      "        -2.1278e-02, -2.6827e-02, -2.1848e-02, -2.2594e-02, -6.5143e-03,\n",
      "        -1.1527e-02, -2.8935e-02, -5.1625e-03, -1.8687e-03, -1.0105e-02,\n",
      "        -4.1683e-02, -2.2400e-02,  1.5109e-02, -1.4821e-02, -1.3116e-02,\n",
      "        -1.3620e-02, -2.6362e-02, -1.6690e-02,  5.6932e-03,  4.1398e-02,\n",
      "         1.6430e-02, -3.3928e-02, -1.6678e-02, -1.6152e-02,  1.3479e-02,\n",
      "         2.0121e-03,  5.7930e-03,  3.2558e-03,  1.2853e-02,  7.1194e-03,\n",
      "         7.1528e-03,  3.8764e-03, -3.1978e-03, -2.1290e-02, -7.5576e-03,\n",
      "         1.0535e-02,  1.0758e-02,  1.9888e-02,  1.7768e-03,  1.0784e-02,\n",
      "         3.1907e-03, -1.2964e-02, -2.2847e-02,  6.4562e-03,  2.1074e-03,\n",
      "        -7.6724e-03, -5.5173e-03, -4.7793e-03,  3.7223e-04,  1.5388e-03],\n",
      "       requires_grad=True)\n",
      "Name of the layer:  fc2.weight\n",
      "Parameters:  Parameter containing:\n",
      "tensor([[-0.0748, -0.0111,  0.0248,  ..., -0.0063,  0.0375,  0.0097],\n",
      "        [ 0.0521, -0.0135,  0.0004,  ...,  0.0302, -0.0003,  0.0080],\n",
      "        [-0.0821,  0.0120, -0.0159,  ...,  0.0237,  0.0106, -0.0148],\n",
      "        ...,\n",
      "        [-0.0170, -0.0004,  0.0040,  ...,  0.0295,  0.0355,  0.0234],\n",
      "        [-0.0549,  0.0005, -0.0288,  ...,  0.0001, -0.0193, -0.0282],\n",
      "        [ 0.0648, -0.0428, -0.0199,  ..., -0.0374, -0.0318, -0.0370]],\n",
      "       requires_grad=True)\n",
      "Name of the layer:  fc2.bias\n",
      "Parameters:  Parameter containing:\n",
      "tensor([-0.0239, -0.0159,  0.0201,  0.0016,  0.0115, -0.0277,  0.0089, -0.0245,\n",
      "         0.0559,  0.0053, -0.0135,  0.0393, -0.0088, -0.0165, -0.0248,  0.0157,\n",
      "        -0.0589, -0.0111, -0.0040, -0.0083, -0.0253, -0.0229, -0.0076, -0.0162,\n",
      "         0.0457,  0.0247,  0.0351, -0.0368,  0.0349,  0.0342, -0.0610,  0.0138,\n",
      "         0.0494, -0.0204,  0.0273, -0.0115, -0.0413, -0.0171, -0.0322, -0.0059,\n",
      "        -0.0565, -0.0111,  0.0144, -0.0403,  0.0077, -0.0765,  0.0040,  0.0357,\n",
      "        -0.0179, -0.0020,  0.0237,  0.0104, -0.0539, -0.0096, -0.0345, -0.0501,\n",
      "        -0.0243, -0.0353,  0.0132, -0.0808, -0.0100, -0.0325, -0.0298,  0.0044,\n",
      "         0.0394,  0.0369,  0.0039,  0.0545, -0.0346,  0.0853,  0.0089, -0.0254,\n",
      "         0.0094, -0.0497,  0.0320, -0.0288, -0.0163, -0.0386, -0.0097, -0.0209,\n",
      "         0.0062,  0.0273, -0.0306, -0.0556,  0.0532, -0.0492, -0.0579,  0.0227,\n",
      "        -0.0444,  0.0690,  0.0698, -0.0166, -0.0004, -0.0249, -0.0111,  0.0235,\n",
      "         0.0356,  0.0260,  0.0123, -0.0179,  0.0307, -0.0479, -0.0413, -0.0345,\n",
      "         0.0269, -0.0444, -0.0277, -0.0072,  0.0134,  0.0355, -0.0200, -0.0032,\n",
      "         0.0434, -0.0431, -0.0547, -0.0294, -0.0076, -0.0150, -0.0289,  0.0869],\n",
      "       requires_grad=True)\n",
      "Name of the layer:  fc3.weight\n",
      "Parameters:  Parameter containing:\n",
      "tensor([[-0.0996, -0.0515,  0.1165,  ..., -0.0144, -0.0295, -0.1198],\n",
      "        [-0.0842, -0.0909,  0.0843,  ..., -0.0217, -0.0537, -0.0438],\n",
      "        [-0.0721, -0.0620,  0.0231,  ..., -0.0192, -0.0513,  0.0097],\n",
      "        ...,\n",
      "        [-0.0873, -0.1635,  0.0122,  ..., -0.0619, -0.0500,  0.0512],\n",
      "        [-0.0139, -0.1169,  0.0723,  ..., -0.0395,  0.0211, -0.0335],\n",
      "        [-0.0566, -0.0223, -0.0480,  ..., -0.0526, -0.0102, -0.0138]],\n",
      "       requires_grad=True)\n",
      "Name of the layer:  fc3.bias\n",
      "Parameters:  Parameter containing:\n",
      "tensor([ 0.0226, -0.0240,  0.0271, -0.0145, -0.0395,  0.0085,  0.0688, -0.0464,\n",
      "        -0.0418, -0.0623,  0.0664,  0.0056,  0.0445, -0.0196, -0.1031,  0.0582,\n",
      "         0.0019,  0.0492, -0.0328,  0.0895, -0.0289, -0.1139,  0.0453, -0.0009,\n",
      "        -0.0751,  0.0390], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, param in Alph_net.named_parameters():\n",
    "    print(\"Name of the layer: \",name)\n",
    "    print(\"Parameters: \",param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xdiJoxEMU0o1",
    "outputId": "9009f3c7-eb2b-4413-c0c7-bbc921696215"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************* ADAM AS OPTIMIZER && CEL AS LOSS FUNC ********************\n",
      "Accuracy of the network on the test images: 83 %\n",
      "Accuracy(USING SKLEARN) of the network on the test images: % 83.33333333333334\n"
     ]
    }
   ],
   "source": [
    "#****************************** Adam as OPTIMIZER && Cross Entropy as LOSS Func ********************************\n",
    "\n",
    "# Evaluate model on test set. This is done in the same way as for training but only till calculating output.\n",
    "correct = 0\n",
    "total = 0\n",
    "prediction=[]\n",
    "Actual=[]\n",
    "with torch.no_grad():\n",
    "    for data in Alph_test_loader:\n",
    "        images, labels = data\n",
    "        outputs = Alph_net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        prediction.extend(predicted)\n",
    "        Actual.extend(labels)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    " \n",
    "\n",
    " \n",
    "#Then,convert output from tensor to numpy format.\n",
    "# convert to class labels\n",
    "# store the predictions\n",
    "prediction=np.array(prediction)\n",
    "Actual=np.array(Actual)\n",
    "\n",
    "print(\"******************* ADAM AS OPTIMIZER && CEL AS LOSS FUNC ********************\")\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "# calculate accuracy of model\n",
    "print('Accuracy(USING SKLEARN) of the network on the test images: %' ,100*accuracy_score(Actual,prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "MYF6y_4Zbqfu",
    "outputId": "3656e29c-782b-4ece-cc29-1cdf728ad5d5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:      P     B     C     V\n",
      "Predicted:      P     B     C     V\n"
     ]
    }
   ],
   "source": [
    "# check predictions by printing the output image for random test inputs.\n",
    "dataiter = iter(Alph_test_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % chr(labels[j]+65) for j in range(4)))\n",
    "\n",
    "outputs=Alph_net(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % chr(predicted[j]+65) for j in range(4)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "177234_a5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
